{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T01:47:36.211992Z",
     "start_time": "2025-11-14T01:47:35.002593Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import sklearn\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f3a0277940ece0",
   "metadata": {},
   "source": [
    "# **Cleaning data:**\n",
    "\n",
    "Such as URLs, hashtags, mentions, special characters, punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abdcdeb122c46757",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T01:47:36.416104Z",
     "start_time": "2025-11-14T01:47:36.245574Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Education Details \\r\\nAugust 2010 to May 2017 BE Electronics & Communication Jabalpur, Madhya Pradesh Takshshila institute of technology\\r\\nJava developer \\r\\n\\r\\n\\r\\nSkill Details \\r\\nJava, Javascript,- Exprience - 6 monthsCompany Details \\r\\ncompany - Wab It Softwere Pvt.  Ltd.\\r\\ndescription - Jr. Java Developer'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"/home/izen-abbas/venv/LSTMs/Final_Categorized.csv\")\n",
    "df['Resume'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "373c1cb2b668326b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T01:47:36.437911Z",
     "start_time": "2025-11-14T01:47:36.434988Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    clean_txt = str(text)\n",
    "    clean_txt = re.sub(r'\\S+@\\S+', ' ', clean_txt)\n",
    "    clean_txt = re.sub(r'http\\S+', ' ', clean_txt)\n",
    "    replacements = {\n",
    "        \"C++\": \"CPLUSPLUS\", \"c++\": \"CPLUSPLUS\",\n",
    "        \"C#\": \"CSHARP\", \"c#\": \"CSHARP\",\n",
    "        \".NET\": \"DOTNET\", \".net\": \"DOTNET\",\n",
    "        \"Node.js\": \"NODEJS\", \"node.js\": \"NODEJS\"\n",
    "    }\n",
    "    for k, v in replacements.items():\n",
    "        clean_txt = clean_txt.replace(k, v)\n",
    "    clean_txt = re.sub(r'[^A-Za-z0-9+\\#\\./\\s]', ' ', clean_txt)\n",
    "    clean_txt = re.sub(r'\\s+', ' ', clean_txt).strip()\n",
    "    inv = {v: k.lower() for k, v in replacements.items()}\n",
    "    for k, v in inv.items():\n",
    "        clean_txt = clean_txt.replace(k, v)\n",
    "    return clean_txt.lower().strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66c6898f49726045",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T01:47:38.009598Z",
     "start_time": "2025-11-14T01:47:36.484717Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Java Developer', 'Business Analyst', 'Enterprise Solutions & ERP',\n",
       "       'Python Developer', 'Data Warehouse & BI Developer',\n",
       "       'Database Developer', 'Database Administrator',\n",
       "       'Systems Administrator', 'Web Developer', 'Cybersecurity Analyst',\n",
       "       'Data Scientist & Analytics', 'HR & Administration',\n",
       "       'Consulting & Professional Services', 'IT Security Engineer',\n",
       "       'Freelance & Independent Contractor', 'Network Administrator',\n",
       "       'Full Stack Developer', 'Mobile Developer', 'Network Engineer',\n",
       "       'Software Engineer', 'IT Director & CIO', 'UI/UX Designer',\n",
       "       'Information Security Analyst', 'IT Program/Portfolio Manager',\n",
       "       'Frontend Developer', 'IT Project Manager'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Resume']=df['Resume'].apply(lambda x: clean_text(x))\n",
    "df['Resume'][0]\n",
    "\n",
    "#before converting into numbers\n",
    "df['Category'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9031a0d72a7f3b",
   "metadata": {},
   "source": [
    "# **Converting Categories into numbers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22c35add121a6031",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T01:47:38.038530Z",
     "start_time": "2025-11-14T01:47:38.019062Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17,  0,  7, 21,  4,  6,  5, 23, 25,  2,  3, 11,  1, 15,  8, 19, 10,\n",
       "       18, 20, 22, 12, 24, 16, 13,  9, 14])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le=sklearn.preprocessing.LabelEncoder()\n",
    "df['Category']=le.fit_transform(df['Category'])\n",
    "\n",
    "#after converting into numbers\n",
    "df['Category'].unique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21832e062b8df739",
   "metadata": {},
   "source": [
    "# **Vectorization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5b470e5e0914af1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T01:47:40.175771Z",
     "start_time": "2025-11-14T01:47:38.072033Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 1866796 stored elements and shape (17110, 29922)>\n",
      "  Coords\tValues\n",
      "  (0, 8720)\t0.1309402842154917\n",
      "  (0, 7601)\t0.4831087842281492\n",
      "  (0, 2706)\t0.21862538495564318\n",
      "  (0, 206)\t0.09213379705841457\n",
      "  (0, 215)\t0.07338619559739704\n",
      "  (0, 8860)\t0.12755674906340367\n",
      "  (0, 5819)\t0.08613881681198299\n",
      "  (0, 14011)\t0.2746553611770998\n",
      "  (0, 15970)\t0.2490121619121687\n",
      "  (0, 20623)\t0.19880645212209477\n",
      "  (0, 26039)\t0.28625559109442017\n",
      "  (0, 13373)\t0.10895014649616216\n",
      "  (0, 26264)\t0.06826891055072465\n",
      "  (0, 14088)\t0.21706337769709697\n",
      "  (0, 7632)\t0.10944134221866895\n",
      "  (0, 24351)\t0.1613341864331558\n",
      "  (0, 14105)\t0.0632660252008347\n",
      "  (0, 9737)\t0.18308910733297792\n",
      "  (0, 17355)\t0.18308910733297792\n",
      "  (0, 5837)\t0.10785287240006153\n",
      "  (0, 28687)\t0.28625559109442017\n",
      "  (0, 24627)\t0.26612242147490894\n",
      "  (0, 21268)\t0.13376305365906602\n",
      "  (0, 7553)\t0.17062410183438148\n",
      "  (0, 14377)\t0.14522316256733567\n",
      "  :\t:\n",
      "  (17109, 26021)\t0.07043359448339516\n",
      "  (17109, 18049)\t0.056157100930003694\n",
      "  (17109, 10091)\t0.07202226892273154\n",
      "  (17109, 13672)\t0.07109019470970034\n",
      "  (17109, 26174)\t0.050514881358377534\n",
      "  (17109, 25464)\t0.08675802063380693\n",
      "  (17109, 9540)\t0.09383993291875566\n",
      "  (17109, 28744)\t0.06741220578058518\n",
      "  (17109, 16359)\t0.1009218452037044\n",
      "  (17109, 5720)\t0.08932622776305946\n",
      "  (17109, 22838)\t0.08337835326115214\n",
      "  (17109, 3658)\t0.09255187756226177\n",
      "  (17109, 24580)\t0.067245324842557\n",
      "  (17109, 26681)\t0.08675802063380693\n",
      "  (17109, 12759)\t0.09138289740705424\n",
      "  (17109, 22078)\t0.1009218452037044\n",
      "  (17109, 17714)\t0.0797872799664093\n",
      "  (17109, 9880)\t0.0846241078949865\n",
      "  (17109, 4951)\t0.1009218452037044\n",
      "  (17109, 720)\t0.09527410226496676\n",
      "  (17109, 14187)\t0.08932622776305946\n",
      "  (17109, 23852)\t0.0968918277538458\n",
      "  (17109, 1017)\t0.10686971970561168\n",
      "  (17109, 3649)\t0.10686971970561168\n",
      "  (17109, 688)\t0.11846533714625664\n"
     ]
    }
   ],
   "source": [
    "tfidf = sklearn.feature_extraction.text.TfidfVectorizer(stop_words='english')\n",
    "resume_tfidf = tfidf.fit_transform(df['Resume'])\n",
    "print(resume_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96083bc4a1d184c",
   "metadata": {},
   "source": [
    "# **Splitting**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfc45c553836b8e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T01:47:40.226663Z",
     "start_time": "2025-11-14T01:47:40.183774Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(resume_tfidf, df['Category'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb5fa3468659118",
   "metadata": {},
   "source": [
    "# **Building by using ML**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af36cb68d6b1cf68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T01:53:37.861569Z",
     "start_time": "2025-11-14T01:47:40.235267Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13 13  9 ...  2  9  6]\n",
      "0.9374634716540035\n"
     ]
    }
   ],
   "source": [
    "#Model#1\n",
    "\n",
    "clf1 = sklearn.svm.SVC(kernel='linear',probability=True)\n",
    "clf1.fit(x_train, y_train)\n",
    "\n",
    "ypred1 = clf1.predict(x_test)\n",
    "\n",
    "print(ypred1)\n",
    "print(sklearn.metrics.accuracy_score(y_test, ypred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1303540858fae8eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T01:54:20.731631Z",
     "start_time": "2025-11-14T01:53:37.900643Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy:\n",
      "0.8296317942723553\n"
     ]
    }
   ],
   "source": [
    "#Model#2\n",
    "\n",
    "clf2=sklearn.linear_model.LogisticRegression(max_iter=500)\n",
    "clf2.fit(x_train, y_train)\n",
    "ypred2=clf2.predict(x_test)\n",
    "print(\"Logistic Regression Accuracy:\")\n",
    "print(sklearn.metrics.accuracy_score(y_test, ypred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98973960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Accuracy:\n",
      "0.988895382817066\n"
     ]
    }
   ],
   "source": [
    "#Model#3 - Random Forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf3 = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "clf3.fit(x_train, y_train)\n",
    "ypred3 = clf3.predict(x_test)\n",
    "print(\"\\nRandom Forest Accuracy:\")\n",
    "print(sklearn.metrics.accuracy_score(y_test, ypred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfce4593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "MODEL COMPARISON\n",
      "==================================================\n",
      "XGBoost                   : 0.9895 (98.95%)\n",
      "Random Forest             : 0.9889 (98.89%)\n",
      "SVM (Linear)              : 0.9375 (93.75%)\n",
      "Logistic Regression       : 0.8296 (82.96%)\n",
      "\n",
      "✓ Best Model: XGBoost with accuracy 0.9895\n"
     ]
    }
   ],
   "source": [
    "#Model Comparison\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "models = {\n",
    "    'SVM (Linear)': sklearn.metrics.accuracy_score(y_test, ypred1),\n",
    "    'Logistic Regression': sklearn.metrics.accuracy_score(y_test, ypred2),\n",
    "    'Random Forest': sklearn.metrics.accuracy_score(y_test, ypred3),\n",
    "}\n",
    "\n",
    "for model_name, accuracy in sorted(models.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{model_name:25} : {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "\n",
    "best_model_name = max(models, key=models.get)\n",
    "print(f\"\\n✓ Best Model: {best_model_name} with accuracy {models[best_model_name]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa96dbd78341cdf2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1e56f97ffbfe4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T01:54:22.636392Z",
     "start_time": "2025-11-14T01:54:20.777357Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ All models saved successfully!\n"
     ]
    }
   ],
   "source": [
    "pickle.dump(tfidf, open('tfidf.pkl', 'wb'))\n",
    "pickle.dump(clf1, open('clf1.pkl', 'wb'))\n",
    "pickle.dump(clf2, open('clf2.pkl', 'wb'))\n",
    "pickle.dump(clf3, open('clf3_rf.pkl', 'wb'))\n",
    "pickle.dump(le, open('le.pkl', 'wb'))\n",
    "pickle.dump(x_test, open('x_test.pkl', 'wb'))\n",
    "pickle.dump(y_test, open('y_test.pkl', 'wb'))\n",
    "\n",
    "print(\"\\n✓ All models saved successfully!\")\n",
    "\n",
    "sample_resume= \"Skills * Programming Languages: Python (pandas, numpy, scipy, scikit-learn, matplotlib), R, Sql, Spark, Scala. * Machine learning: Deep Learning, CNN, RNN, Transformers, Regression, SVM, Random Forest, Ensemble Methods, Natural Language processing, Dimensionality reduction, Cluster Analysis, Time Series Analysis. * Database Visualizations: Mysql, PostgresSQL, MongoDB, Tableau, PowerBI, D3.js. * Others: Regular Expression, HTML, CSS, Git, Docker, Kubernetes, AWS, GCP, computer vision - OpenCV. Education Details Master of Science in Data Science, Stanford University, 2018. Bachelor of Technology in Computer Science, IIT Delhi, 2016. Professional Experience Senior Data Scientist - Tech Innovations Co. (2018 - Present) Skill Details PYTHON- Exprience - 60 months R- Exprience - 36 months SPARK- Exprience - 24 months Company Details company - Tech Innovations Co. description - Led the development of a state-of-the-art recommendation engine using collaborative filtering and deep learning, resulting in a 25% increase in user engagement. Developed and deployed NLP models for sentiment analysis on customer feedback, improving product iteration speed by 40%. Managed a cloud-based data pipeline (AWS/GCP) processing over 1TB of data daily. Mentor junior data scientists on best practices for model building, validation, and deployment.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcad6d503a11839d",
   "metadata": {},
   "source": [
    "# **Prediction System**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effdaea6804dc854",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T01:54:22.663770Z",
     "start_time": "2025-11-14T01:54:22.643670Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "SAMPLE RESUME PREDICTIONS\n",
      "==================================================\n",
      "\n",
      "Model#1 (SVM Linear):             Data Scientist & Analytics\n",
      "Model#2 (Logistic Regression):    Python Developer\n",
      "Model#3 (Random Forest):          Python Developer\n",
      "Model#4 (XGBoost):                Data Scientist & Analytics\n"
     ]
    }
   ],
   "source": [
    "cleaned_resume = clean_text(sample_resume)\n",
    "vectorized_resume = tfidf.transform([cleaned_resume])\n",
    "\n",
    "# Get predictions from all models\n",
    "prediction1 = clf1.predict(vectorized_resume)[0]\n",
    "prediction2 = clf2.predict(vectorized_resume)[0]\n",
    "prediction3 = clf3.predict(vectorized_resume)[0]\n",
    "\n",
    "category_mapping = dict(enumerate(le.classes_))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"SAMPLE RESUME PREDICTIONS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nModel#1 (SVM Linear):             {category_mapping.get(prediction1, 'Unknown')}\")\n",
    "print(f\"Model#2 (Logistic Regression):    {category_mapping.get(prediction2, 'Unknown')}\")\n",
    "print(f\"Model#3 (Random Forest):          {category_mapping.get(prediction3, 'Unknown')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
